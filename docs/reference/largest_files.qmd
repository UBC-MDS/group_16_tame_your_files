# largest_files { #tame_your_files.largest_files }

```python
largest_files(root, n=10)
```

Recursively scan a directory and return the n largest files.

## Parameters {.doc-section .doc-section-parameters}

| Name   | Type   | Description                                              | Default    |
|--------|--------|----------------------------------------------------------|------------|
| root   | Path   | Root directory to scan. All subdirectories are included. | _required_ |
| n      | int    | Maximum number of files to return.                       | `10`       |

## Returns {.doc-section .doc-section-returns}

| Name   | Type             | Description                                                             |
|--------|------------------|-------------------------------------------------------------------------|
|        | list\[FileInfo\] | Files sorted by size in descending order. At most n files are returned. |

## Notes {.doc-section .doc-section-notes}

- Only regular files are considered.
- Directories are ignored.
- Unreadable files, broken symlinks, and permission errors
are skipped silently.

## Examples {.doc-section .doc-section-examples}

```python
>>> import tempfile
>>> from pathlib import Path
>>> with tempfile.TemporaryDirectory() as tmp:
...     root = Path(tmp)
...     _ = (root / "a.txt").write_text("a")
...     _ = (root / "b.txt").write_text("bb")
...     largest_files(root, n=1)[0].path.name
'b.txt'
```